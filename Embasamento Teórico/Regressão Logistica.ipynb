{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Binaria\n",
    "---\n",
    "  \n",
    "  \n",
    "  \n",
    "<div align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"https://aigeekprogrammer.com/wp-content/uploads/2019/10/Logistic-Regression-learning.png\">\n",
    "</div>\n",
    "\n",
    "Um modelo previsor de classificação se refere a um problema no qual precisamos declarar de forma clara se um elemento faz parte de um determinado grupo ou não.  \n",
    "\n",
    "No mundo atual, estamos rodeados de modelos que fazem essas classificações para a gente, de forma rotineira, ao ponto em que algumas vezes nem sabemos de sua existencia. Por exemplo:  \n",
    "- Dado o comportamento recente de um usuário, se é um usuário ativo ou não.  \n",
    "- Um modelo que classifica se o novo email recebido deve ir para a caixa de spam ou não.  \n",
    "- Se o local onde você está fazendo compra é um lugar de seu costume e definir se a compra de trata de um fraude ou não.  \n",
    "\n",
    "Para fazer tal previsão, primariamente, é necessário um conjunto onde podemos treinar nossos dados, atraves de variaveis que representam o comportamente anterior e seu resultado, ou seja, o modelo usará os dados de treino para encontrar a melhor forma possível para rotular os elementos. Por consequencia, os dados de treino deve ser suficientemente representativo em relação ao problema que desejamos prever e ter uma amostra grande o suficiente para representar cada classe possível.\n",
    "\n",
    "Existem diversos modelos de previsão disponíveis para esses diversos problemas, então de maneira geral, não existe um modelo especificado para cada situação, em vez disso, é recomendado que seja testado o maior número de modelos possível de acordo com a restrição de tempo e renda disponibilizada, para verificar qual deles tras o melhor resultado dentre o problema envolvido. \n",
    "\n",
    "Como o modelo preditivo se baseia na ideia das classificações, uma das maneira que verificamos essa capacidade, vem de acordo com a acuracia dos resultados finais gerados pelo modelo ao completar a tarefa sugerida. \n",
    "\n",
    "Geralmente para a classificação binária nos deparamos com um clase em seu comportamento comum e o outra classe em seu estado anormal. Por exemplo, para a situação de prever spam, temos que em o email está em seu estado comum e o spam é seu estado \"anormal\". Também é comum, mas não é regra, classificar como 0 o rótulo de estado comum e 1 como estado anormal, porém para a construção de um Behaviour Score, pois é essencial para o Score que não haja betas invertidos, sendo um valor apenas que aumenta e nunca diminui. \n",
    "\n",
    "Para esse estudo, faremos uso da Regressão Lógistica, pois além de ser um método muito popular para a classificação binária, ela também contém um certa relação de uso com as redes neurais, que será aprofundado futuramente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística \n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como boa parte das técnicas estatísticas, a Regressão Logística foi criada no século XVIII graças a alguns estudos sobre crescimento populacional. Segundo CRAMER (2002), após 40 anos, esse estudo foi reutilizado para a previsão populacional de alguns países Europeus, porém recebeu sua primeira publicação apenas em 1845, através de Pierre-François Verhust. Nessa época, ela foi chamada de curva logística. Logo caracterizou-se por ser capaz de descrever as relações entre uma variável dependente qualitativa binária, em relação ao restante das variáveis. Devido à natureza da Regressão Logística, sua utilidade e campo de aplicação são vastos e permitem aplicação em diversas áreas de estudo. Hoje em dia, percebe-se que há uma preferência sobre esse método no mercado de crédito, pois permite a previsão de pessoas que não pagarão suas pendências, com uma função relativamente simples.  \n",
    "\n",
    " Pois, esse método regressivo ser tornou componente integral de qualquer análise de dados, devido a sua capacidade de descrever a relação entre a variável resposta e uma ou mais viáveis exploratórias. E frequentemente, nossa variável resposta é uma variável discreta, tendo apenas dois ou poucos mais valores. Nas últimas décadas o modelo de Regressão logistica  se tornou o padrão para análises desse tipo de situação. (LEMESHOW; HOSMER, 2000)\n",
    " Em suma, analisaremos o comportamento de adimplentes, atribuindo o valor 1 para os inadimplentes, e 0 para os adimplentes. Assim, conseguiremos ver a taxa relativa de forma mais compreensível. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "Y=\n",
    "  \\begin{cases}\n",
    "    0, & \\text{se o usuario é inadimplente.} \\newline\n",
    "    1, & \\text{caso contrário.} \n",
    "  \\end{cases}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como citado anteriormente, faremos uso dessa forma, pois colocando o adimplente como 1, ao multiplicarmos essa flag, teremos um incremento no score final do usuario ao fim da previsão, e por conveniencia evitamos um beta negativo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O Modelo Logístico\n",
    "--- \n",
    "\n",
    "O Modelo Logístico é um modelo probabilístico, prevê outputs binários e é recomendado para observar a chance de um elemento fazer parte de um determinado grupo ou evento. Abaixo, listamos três exemplos de aplicação de classificação binária.\n",
    "\n",
    "* Se um usuário é ativo ou não, de acordo com o seu comportamento recente;\n",
    "* Se o e-mail recebido deve ir ou não para a caixa de spam;\n",
    "* Se o local de compra do usuário é de seu costume e a partir disso identificar se é uma fraude.\n",
    "\n",
    "Para compreendermos a Regressão Logística, é necessário englobarmos alguns conceitos do Modelo.\n",
    "\n",
    "A função logística é o que denominamos como função sigmoide. Possui uma aparência curva, semelhante a um \"S” e, apesar de ser frequentemente associada à logística, contém uma gama diversa de funções, assim como as expressas na figura 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Gjl-t%28x%29.svg/1280px-Gjl-t%28x%29.svg.png\" >\n",
    "    <figcaption>Funções Sigmoides</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função logística, por sua vez, tem a seguinte forma:\n",
    "$$\\sigma(t)=\\frac{e^{t}}{e^{t}+1}=\\frac{1}{1+e^{-t}}$$\n",
    "\n",
    "A Regressão Logística é análoga à Regressão Linear, pois sofre uma transformação em sua função que a faz ser interpretada como uma probabilidade em relação a apenas dois cenários possíveis, para esse estudo, temos o adimplente e o inadimplente. Já o Modelo Linear, não possui boa capacidade de previsão para cenários probabilísticos, porque apresenta maior sensibilidade quando é necessário lidar com outliers, o que leva a incoerências nas interpretações.\n",
    "\n",
    "Matheus Facure (2017) ilustra essa diferença com uma agência de seguros, em que é necessário decidir se deve ou não segurar um carro a partir das informações sociais de seus donos. Para essa análise, saber apenas o tempo de autoescola não é o suficiente. Dessa forma, Facure (2017) elabora um exemplo com 15 pessoas e duas variáveis: tempo na autoescola e se já sofreram ou não acidente.\n",
    "\n",
    "Abaixo, os dados em um gráfico, sendo o eixo y, a informação se a pessoa sofreu um acidente (1) ou não (0); e o eixo x, o tempo de autoescola:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"https://matheusfacure.github.io/img/tutorial/binaria.png\" >\n",
    "    <figcaption>Funções Sigmoides</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir desse gráfico, observamos que a maioria daqueles que sofreram um\n",
    "acidente de carro passou pouco tempo na autoescola, mas não conseguimos prever\n",
    "a probabilidade da pessoa sofrer um acidente, com base no tempo que durou a\n",
    "autoescola.\n",
    "\n",
    "Uma das alternativas, então, seria utilizar a Regressão Linear. Como exemplo,\n",
    "Facure (2017a) usa o limiar 0,5. Nesse caso, pessoas com previsão de acidente acima\n",
    "disso seriam consideradas de alto risco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"https://matheusfacure.github.io/img/tutorial/bi_linregr.png\" >\n",
    "    <figcaption>Funções Sigmoides</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com Facure, apesar de prevermos que todos à direita da curva pontilhada não sofreriam um acidente, não conseguiríamos identificar outliers. Exemplo: uma pessoa que fez 100 horas de autoescola. O algoritmo de previsão não deveria dar muita atenção a essa pessoa e se concentrar nas regiões de fronteira,mas isso não acontece com a Regressão Linear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"https://matheusfacure.github.io/img/tutorial/bi_lin_out.png\" >\n",
    "    <figcaption>Funções Sigmoides</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse outlier (pessoa com 100 horas de autoescola) faz o gráfico ser puxado para a direita. Com isso, pessoas de baixo risco seriam classificadas com alta probabilidade de sofrer acidentes e aquelas com mais de 70 horas teriam uma probabilidade negativa de acidente, o que não tem sentido.\n",
    "\n",
    "Como podemos ver, o Modelo Linear apresenta diversos problemas para a nossa análise. Porém, mas a frente, também veremos que este faz parte do Modelo Logístico, por isso demostramos, abaixo, a função do Modelo Linear:\n",
    "\n",
    "$$\\text{Modelo Linear}$$\n",
    "$$y=\\beta_0+\\beta_1x_1+...+\\beta_nx_n+\\varepsilon$$\n",
    "$$ou$$\n",
    "$$y=X\\beta+\\varepsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função logística, por sua vez, consegue lidar com qualquer número real para $t, (t\\in\\mathbb{R})$ e sua saída é um valor entre zero e um. Dentro dessa forma de modelagem, podemos interpretar esse valor como uma probablidade.\n",
    "\n",
    "A função logística padrão com $\\sigma:\\mathbb{R}\\to(0,1)$ a definida seguir com:\n",
    "\n",
    "$$\\sigma(t)=\\frac{e^{t}}{e^{t}+1}=\\frac{1}{1+e^{-t}}$$\n",
    "\n",
    "Sendo o gráfico gerado na figura abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/600px-Logistic-curve.svg.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então vamos assumir que $z$ seja uma Regressão Linear simples com apenas uma variável independente $x$. Podemos definir $z$ da seguinte forma: \n",
    "\n",
    "$$z=\\beta_0+\\beta_1x$$\n",
    "\n",
    "Por consequencia, aplicando uma transformação de achatamento na Regressão Linear, nossa função toma a seguinte forma: \n",
    "\n",
    "$$\\sigma(z)={{1}\\over{1+e^{-z}}}={{1}\\over{1+e^{-\\beta_0+\\beta_1x_1}}}=p(x)$$\n",
    "\n",
    "E de maneira similar para estudos onde temos mais de uma varivel explicatória para $X$, podemos expressar nossa função como:\n",
    "\n",
    "$$z=\\beta_0+\\beta_1x_1+...+\\beta_{n-1}+\\beta_n$$\n",
    "\n",
    "E em seguida:\n",
    "\n",
    "$$\\sigma(z)={{1}\\over{1+e^{-z}}}={{1}\\over{1+e^{-\\beta_0+\\beta_1x_1+...+\\beta_{n-1}+\\beta_n}}}$$\n",
    "\n",
    "E como dito anteriormente, interpretamos $S(z)$ como a probabilidade da variavel dependente $Y$. É valido mencionar que é facilmente aplicavel a inversa da função anterior atravez do uso de um log, onde teremos:\n",
    "\n",
    "$$g(x)=\\ln({{1}\\over{1+e^{-z}}})=\\beta_0+\\beta_1x_1+\\ldots+\\beta_nx_n$$\n",
    "\n",
    "O uso desse artifício pode ser útil para uma análise mais detalhada sobre determinado aspecto do modelo, como possível correlação de variáveis, que pode causar inflação nos valores do score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um outro ponto extremamente relevante da função sigmoide é que, ao retirarmos a sua derivada, nos deparamos com uma função extremamente útil para a função de ativação das Redes Neurais, devido a sua eficiência computacional. \n",
    "\n",
    "$$\\frac{d\\sigma(z)}{dz}  =  \\sigma(z)( 1- \\sigma(z))$$\n",
    "\n",
    "Sendo a demonstração feita a seguir: \n",
    "\n",
    "$$\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "E fazendo $X\\beta=z$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d\\sigma(z)}{dz}\n",
    "&= \\frac{1}{1+e^{-z}} \\\\\n",
    "&= (1+e^{-z})^{-1} \\\\\n",
    "&= (-1) \\cdot (1+e^{-z})^{-2} \\cdot (-e^{-z}) \\\\\n",
    "&= \\frac{e^{-z}}{(1+e^{-z})^{-2}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "É recomendada a simplificação dessa ultima formula, portanto, faremos os seguintes passos: \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{e^{-z}}{(1+e^{-z})^{-2}}\n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot \\frac{e^{-z}}{(1+e^{-z})} \\\\\n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot \\frac{e^{-z}\\color{red}{+1-1}}{(1+e^{-z})} \\\\\n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot [\\frac{(1+e^{-z})}{(1+e^{-z})}-\\frac{1}{(1+e^{-z})}] \\\\ \n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot [1-\\frac{1}{(1+e^{-z})}] \\\\\n",
    "&= \\sigma(z)[1-\\sigma(z)]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque é recomenda a utilização da derivada da sigmoíde como $\\sigma(z)[1-\\sigma(z)]$ em vez de $\\frac{e^{-z}}{(1+e^{-z})^{-2}}$? \n",
    "\n",
    "Pois, quando for necessário a utilização de uma ferramenta chamada backpropagation para a amenização dos erros nas Redes Neurais, já teremos o cálculo da função  $\\sigma(z)$, o que facilita os diversos cálculos computacionais executados. \n",
    "\n",
    "Como esses cálculos são feitos diversas vezes em diversas situações distintas, ganhos de milésimos para cada execução nos leva a economias discrepantes de tempo ao longo da execução. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dando continuidade às validações teóricas de um modelo, também abordaremos conceitos, como a função de custo, visto que deseja-se evitar erros no momento de aplicarmos um modelo de previsão. Para isso, objetivamos minimizar as diferenças entre nossas estimativas e valores observados o máximo possível. Dessa forma, a seguir daremos uma olhada nesse tópico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função Custo \n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O intuito da modelagem é que ela nos dê valores estimados, resultantes de $\\hat{y}=\\sigma(X\\hat{\\beta})$, que esteja o mais próximo possível dos valores observados nas amostras. Para isso nosso objetivo é que cheguemos em valores para $\\hat{\\beta}$ de forma que ele minize os erros. E para termos uma visão objetiva sobre a performance do nosso modelos, iremos utilizar da função custo. \n",
    "\n",
    "Este conceito, além de ser extremamente relevante para o estudo de Regressões, ele será também de extrema importância para a conceituação do vetor gradiente descendente que veremos mais profundamente um pouco mais a frente. Mas para inicio do tema, também faremos algumas observações sobre as funções convexas e não convexas que será relevante mais adiante. \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-1-4842-4246-9_6/MediaObjects/332789_2_En_6_Fig1_HTML.png\">\n",
    "    <figcaption>Função Convexa e Não-convexa</figcaption>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "É rotineiro o uso do EQM como função custo para a análise dos resíduos na Regressão Linear, tendo a seguinte forma:  <br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Função Custo: Regressão Linear}$$\n",
    "$$EQM=\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y_i}-y_i)^2$$\n",
    "\n",
    "\n",
    "Porém, esse método para a análise dos resíduos não é recomendado para a Regressão Logística, pois sua utilização gera muitos pontos de maximos e mínimos locais o que dificulta a otimização para os valores dos parametros $\\hat{\\beta}$. Esse resultado estranho ocorre devido a função sigmoide apresentada na Regressão Logística, ser uma função não-linear. E como estamos interessado em um gráfico convexo, de forma que facilite encontrar nosso ponto de otimização, essa não se demonstra uma boa forma de fazermos a nossa análise.\n",
    "\n",
    "E para isso, quando estamos lidando com a regressão logística, a função custo utilizada é a Entropia Cruzada, também conhecida como Log-Loss.\n",
    "\n",
    "De maneira enxuta, a **entropia cruzada**, nada mais é que identificarmos a diferença das distribuições probabilisticas entre os valores reais dos valores observados, enquanto que para o EQM, avaliamos a diferença geométrica média entre os elementos. \n",
    "\n",
    "A vantagem dessa metódologia, é que ao verificarmos as diferenças entre os valores observados dos previstos, ela gera um formato curvo que não apresenta pontos de máximos e mínimos locais, mas sim um ponto global, e isso nos dá suporte para minimizar a **entropia cruzada** de forma mais eficiente e precisa. \n",
    "\n",
    "$$\\text{Função Custo: Regressão Logística}$$\n",
    "$$L=\\frac{1}{n}\\sum_{i=1}^{n}L(\\hat{y_i},y_i)=-\\frac{1}{n}\\sum_{i=1}^{n}[y_i\\ln{(\\hat{y})}+(1-y_i)\\ln(1-\\hat{y_i})]$$\n",
    "\n",
    "Podendo ser simplificada da seguinte forma:\n",
    "$$\n",
    "L=\n",
    "  \\begin{cases}\n",
    "    -\\log(\\hat{y}) & \\text{se, y = 1} \\newline\n",
    "    -\\log(1-\\hat{y}), & \\text{se, y = 0} \n",
    "  \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para uma conceituação mais clara de como chegamos nessa forma e porque ela é a função de custo envolvida na regressão logística, vamos fazer uma transição sobre o funcionamento do modelo. \n",
    "\n",
    "Então, seja Y uma variavel aleatória, e como citado no inicio do estudo, um classificador binário, podemos enxergar Y da seguinte forma:\n",
    "\n",
    "$$ \n",
    "Y=\n",
    "  \\begin{cases}\n",
    "    0, & \\text{se o usuario é inadimplente.} \\newline\n",
    "    1, & \\text{caso contrário.} \n",
    "  \\end{cases}\n",
    "$$ \n",
    "\n",
    "Vamos supor então, que temos uma amostra com n elementos independentes, e vizualizando os pares como $(\\textbf{x}, y_i), i= 1, 2,..., n, $ onde cada $y_i$ denota um resultado dicotomico das variaveis independentes $x_i$, sendo que para os casos multivariados, desejamos obter os valores estimados para o vetor $\\beta'=(\\beta_0, \\beta_1, ... , \\beta_m). Sendo $ \n",
    "\n",
    "Assim, cada Y pode seguir uma distribuição de Bernoulli: \n",
    "\n",
    "$$P(y \\mid \\theta) = \\theta_{i}^{y_i} \\cdot (1-\\theta_i)^{1-y_i}, i=0,1,2,...,n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo: \n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "y = \\text{Evento Ocorrido.}  \\\\\n",
    "\\theta = \\text{Probabilidade de ocorrer o evento de interesse}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Como há um sequencia de um mesmo evento, e nosso objetivo é predizer um probabilidade desconhecida $\\theta$, pode ser de interesse a identificação da função do Máxima Verossimilhança que minimiza o erros dos parametros estimados. Que nos dá um função que se assemelha ao formula anterior. \n",
    "\n",
    "$$l(\\beta)=\\prod_{i=1}^{n}\\theta_{i}^{y_i}(1-\\theta_i)^{1-y_i}$$\n",
    "\n",
    "Porém isso nos leva a problemas onde quando multiplicamos diversos valores pequenos, temos como resultado uma saída com valores ainda menores. Uma forma de transpor essa problematica é a da aplicação do log em nossa função de verossimilhança. De forma que permita manipulações algebricas mais convenientes para a aplicação e interpretação de resultados. \n",
    "\n",
    "Que nos leva a função custo da entropia cruzada, apresentada anteriormente. \n",
    "\n",
    "$$\\ln l(\\beta)=\\ln \\prod_{i=1}^{n}\\theta_{i}^{y_i}(1-\\theta_i)^{1-y_i}=\\sum_{i=1}^{n}[y_i\\ln{(\\theta_{i})}+(1-y_i)\\ln(1-\\theta_{i})]$$\n",
    "\n",
    "Dessa forma, ao diferenciarmos $L(\\theta)$ em relação a $\\beta_0$ e $\\beta_1$, e as igualando as zero, teremos, que\n",
    "\n",
    "$$\\frac{dL(\\theta)}{d\\beta_0}=\\sum_{i=1}^{n}[y_i-\\sigma(x_i)]$$\n",
    "\n",
    "$$\\frac{dL(\\theta)}{d\\beta_1}=\\sum_{i=1}^{n}x_i \\cdot[y_i-\\sigma(x_i)]$$\n",
    "\n",
    "Devido a essas equações serem não-lineares. Ele necessitam de um método iterativo para sua solução.\n",
    "\n",
    "Que nos leva ao próximo tópico do estudo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O Gradiente Descendente\n",
    "--- \n",
    "\n",
    "O gradiente descendente é um algoritmo iterativo de otimização para métodos onde é necessário lidar com dados multidimensionais. \n",
    "\n",
    "E sua concepção é semelhante a outros métodos interativos, onde ele tenta encontrar um valor que encaixa dentro do resultado necessário, utilizando uma pouco da conceituação do vetor gradiente que é selecionado um ponto aleatorio dentro de um plano geométrio multidimensional. A partir desse ponto, ele utiliza da direção disponibilizada pelo derivada da função de forma que aponte a direção mais rapido para chegar ao ponto de maximo e mínimo da forma mais rápido possível. \n",
    "\n",
    "De maneira matemática, a formula que iremos utilizar será: \n",
    "\n",
    "$\n",
    "Repetir: x_{i}:=x_{i-1} - \\alpha \\frac{df(x_{i-1})}{dx}\n",
    "$\n",
    "\n",
    "Sendo $\\alpha$ a taxa de aprendizado que iremos utilizar uma constante positiva. O valor desse $\\alpha$ é um fator muito importante, pois os pontos gerados pela função do gradiente descendente tentem a diminiur a velocidade e caso não seja selecionado uma taxa de aprendizado de maneira adequada, iremos topar em algum problemas. Pois, se selecionarmos um valor muito baixo, a velocidade para encontrar o ponto de mínimo é muito devagar e por consequencia a estimação dos parametros será extremamente demorada. \n",
    "\n",
    "Agora, caso seja selecionado uma taxa de aprendizado muito alta, pode ocorrer de ultrapassarmos o ponto de mínimo ótimo, e o algoritmo continuar andando indefinidamente pois nunca encontrará o ponto ótimo.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img width=\"615\" height=\"597\" src=\"https://aimlsite.files.wordpress.com/2018/03/gradient-descent.png?w=1008\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De maneira prática, a utilização do gradiente descendente, significa que o valor de x na iteração atual é o seu\n",
    "valor somado com alguma fração do gradiente da função do seu valor anterior. \n",
    "\n",
    "O método se dá inicio com um valor aleatório, e chega a seu fim, quando o valor de $x_i = x_{i-1}$ ou o delta entre os valores for extremamente insigficante. \n",
    "\n",
    "Utilizando da imagem acima para demonstração de sua utilização, o interesse é encontrar o ponto mínimo da função. O ponto de início se dá em $x_0$, e note que os passo gerado pela derivada da função multiplicada por uma taxa de aprendizado arbitrário, é o maior passo gerado (seta em vermelho), pois como já citado, o início se dá como passos largos, mas com o decorrer dos passos, essa velocidade tende a diminuir. \n",
    "\n",
    "No segundo passo, a derivada da função em $x_1$ se torna menor, e ela vai diminuindo, até que em um $x_i$ e sua derivada da função $f'(x_i)$ a diferença e tão minúscula, que podemos considera-la como 0. Portanto, chegamos ao pontos ótimos de interação dos parametros. \n",
    "\n",
    "Para o caso multivariado, este conceito permance o mesmo. Se diferenciando apenas em ajustar individualmente cada dimensão de x em direção ao valor mínimo. \n",
    "\n",
    "Ou seja: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Repetir: \\overrightarrow{x_{i}}:=\\overrightarrow{x}_{i-1} - \\alpha \\cdot \\nabla \\cdot f(\\overrightarrow{x}_{i-1}) $$\n",
    "\n",
    "Dessa forma, para cada interação $i$, todas as dimenções serão ajustadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo uso da formula padrão da Log-Loss, faremos uso de derivadas para encontrar seu ponto de otimização.\n",
    "\n",
    "$$L=-\\frac{1}{n}\\sum_{i=1}^{n}[y_i\\ln{(\\hat{y})}+(1-y_i)\\ln(1-\\hat{y_i})]$$\n",
    "\n",
    "Então substitituindo nosso $\\hat{y}$ por $\\sigma(X\\beta)$ e diferenciando $L$ podemos encontrar o valor otimo dos parametros. \n",
    "\n",
    "Para simplificamos um pouco a explicação das derivadas envolvidas, farei uso da Função Perca, que é a mesma formula da Função Custa aplicada apenas um elemento. Então para nossa função perca, toma-se a seguinte formula: \n",
    "\n",
    "$$L=-(y_i\\ln{(\\hat{y})}+(1-y_i)\\ln(1-\\hat{y_i}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo a seguintes derivadas \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{dL}{d\\hat{y}}\n",
    "&= \\frac{1-y}{1-\\hat{y}}-\\frac{y}{\\hat{y}} \\\\\n",
    "&= \\frac{-y+\\hat{y}y+\\hat{y}-\\hat{y}y}{\\hat{y}(1-\\hat{y})} \\\\\n",
    "&= \\frac{\\hat{y}-y}{\\hat{y}(1-\\hat{y})}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**OBS:** Lembre-se que $\\hat{y}=\\sigma(X\\beta)$, e que $\\sigma(X\\beta)$ é a função sigmoíde. Portanto para o próximo passo, faremos a derivada da função sigmóide da seguinde forma: \n",
    "\n",
    "$$\\frac{1}{1+e^{-X\\beta}}$$\n",
    "\n",
    "E fazendo $X\\beta=z$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d\\sigma(z)}{dz}\n",
    "&= \\frac{1}{1+e^{-z}} \\\\\n",
    "&= (1+e^{-z})^{-1} \\\\\n",
    "&= (-1) \\cdot (1+e^{-z})^{-2} \\cdot (-e^{-z}) \\\\\n",
    "&= \\frac{e^{-z}}{(1+e^{-z})^{-2}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Agora para simplifcar a formula, faremos os seguintes passos: \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{e^{-z}}{(1+e^{-z})^{-2}}\n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot \\frac{e^{-z}}{(1+e^{-z})} \\\\\n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot \\frac{e^{-z}\\color{red}{+1-1}}{(1+e^{-z})} \\\\\n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot [\\frac{(1+e^{-z})}{(1+e^{-z})}-\\frac{1}{(1+e^{-z})}] \\\\ \n",
    "&= \\frac{1}{(1+e^{-z})} \\cdot [1-\\frac{1}{(1+e^{-z})}] \\\\\n",
    "&= \\sigma(z)[1-\\sigma(z)]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Como $\\hat{y}=\\sigma(z)$, podemos simplificar ainda mais o resultado anterior como: \n",
    "\n",
    "$$\\frac{d\\sigma(z)}{dz} = \\hat{y} \\cdot (1-\\hat{y})$$\n",
    "\n",
    "Então pra finalizarmos as formulas de otimização da função Log, teremos: \n",
    "\n",
    "$$\\frac{dL}{dz}=\\frac{dL}{d\\hat{y}} \\cdot \\frac{d\\hat{y}}{dz}= \\frac{\\hat{y}-y}{\\hat{y}(1-\\hat{y})} \\cdot \\hat{y} \\cdot (1-\\hat{y}) = \\hat{y} - y$$\n",
    "\n",
    "De forma que nossa função de custo para a otimização demonstrada, é apenas a adição da somatória: \n",
    "\n",
    "$$L=\\frac{1}{n}  \\sum_{i-1}^{n}(\\hat{y} - y)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
